{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a116f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from model import LogisticRegressionModel\n",
    "from federated import train_federated\n",
    "from client import get_dataloaders_per_client, get_local_models\n",
    "from metrics import compare_global_local, plot_auc_heatmap\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48adf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders créés pour 3 clients avec input_dim = 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Chargement des données CSV\n",
    "df_fr = pd.read_csv(\"/home/onyxia/work/Federated_Learning_Milliman/data/french_data.csv\").dropna()\n",
    "df_be = pd.read_csv(\"/home/onyxia/work/Federated_Learning_Milliman/data/belgium_data.csv\").dropna()\n",
    "df_eu = pd.read_csv(\"/home/onyxia/work/Federated_Learning_Milliman/data/european_data.csv\").dropna()\n",
    "\n",
    "# 2. Nom de la colonne cible\n",
    "label_col = \"Sinistre\"  # ⚠️ Remplace ceci si ta colonne cible a un autre nom\n",
    "\n",
    "# 3. Fonction de validation des colonnes\n",
    "def check_columns_consistency(dfs, label_col):\n",
    "    base_cols = dfs[0].drop(columns=[label_col]).columns\n",
    "    for i, df in enumerate(dfs[1:], start=1):\n",
    "        other_cols = df.drop(columns=[label_col]).columns\n",
    "        if not all(base_cols == other_cols):\n",
    "            raise ValueError(f\"Les colonnes des DataFrames ne sont pas cohérentes entre df[0] et df[{i}].\")\n",
    "\n",
    "# 4. Fonction de prétraitement et DataLoader\n",
    "def create_dataloaders_from_dfs(dfs, label_col, batch_size=32, scale=True):\n",
    "    check_columns_consistency(dfs, label_col)\n",
    "    loaders = []\n",
    "    scaler = StandardScaler() if scale else None\n",
    "\n",
    "    # Ajuster le scaler globalement pour homogénéiser les échelles\n",
    "    if scale:\n",
    "        all_X = pd.concat([df.drop(columns=[label_col]) for df in dfs])\n",
    "        scaler.fit(all_X)\n",
    "\n",
    "    for df in dfs:\n",
    "        X = df.drop(columns=[label_col]).values.astype(np.float32)\n",
    "        y = df[label_col].values.astype(np.float32)\n",
    "        if scale:\n",
    "            X = scaler.transform(X)\n",
    "        X_tensor = torch.tensor(X)\n",
    "        y_tensor = torch.tensor(y)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        loaders.append(loader)\n",
    "\n",
    "    return loaders\n",
    "\n",
    "# 5. Construction des DataLoaders\n",
    "dfs = [df_fr, df_be, df_eu]\n",
    "train_loaders = create_dataloaders_from_dfs(dfs, label_col=label_col, batch_size=32)\n",
    "\n",
    "# 6. Récupération de la dimension d'entrée\n",
    "input_dim = dfs[0].drop(columns=[label_col]).shape[1]\n",
    "\n",
    "print(f\"DataLoaders créés pour {len(train_loaders)} clients avec input_dim = {input_dim}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model, metrics = train_federated(\n",
    "    train_loaders, input_dim=input_dim, algo=algo, T=20, C=1.0,\n",
    "    E=3, B=32, lr=0.05, mu=0.0,eta=0.01, beta1=0.9, beta2=0.99,\n",
    "    tau=1e-6, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebc84a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Choisir l'algorithme : 'fedavg', 'fedprox', 'fedopt_adam', 'fedopt_yogi', 'fedopt_adagrad'\u001b[39;00m\n\u001b[32m      2\u001b[39m algo = \u001b[33m'\u001b[39m\u001b[33mfedavg\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m global_model, metrics = \u001b[43mtrain_federated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Une liste de DataLoader très petits (voir plus bas)\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Un petit nombre de variables explicatives (par exemple 10)\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfedavg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Pour commencer rapidement ; ensuite tester 'fedprox'\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# Seulement 2 rounds fédérés\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# Prendre tous les clients à chaque round\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mE\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# Une seule époque locale\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# Mini-batch de 8\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Apprentissage local rapide\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# Pas de régularisation FedProx pour l’instant\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Utiliser CPU pour compatibilité\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Federated_Learning_Milliman/federated_logistic_regression/federated.py:36\u001b[39m, in \u001b[36mtrain_federated\u001b[39m\u001b[34m(train_loaders, input_dim, algo, T, C, E, B, lr, mu, eta, beta1, beta2, tau, device)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[32m     35\u001b[39m     local_model = copy.deepcopy(global_model)  \u001b[38;5;66;03m# Assurer que chaque client a une copie du modèle global\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     updated_model = \u001b[43mlocal_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfedprox\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfedprox\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     client_models.append(updated_model)\n\u001b[32m     44\u001b[39m     client_sizes.append(\u001b[38;5;28mlen\u001b[39m(train_loaders[k].dataset))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Federated_Learning_Milliman/federated_logistic_regression/client.py:58\u001b[39m, in \u001b[36mlocal_update\u001b[39m\u001b[34m(model, dataloader, epochs, batch_size, learning_rate, global_weights, mu, device)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m     57\u001b[39m         \u001b[38;5;66;03m# Entraînement avec X_batch, y_batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m         output = model(X_batch.to(device))\n\u001b[32m     60\u001b[39m         loss = nn.BCELoss()(output.view(-\u001b[32m1\u001b[39m), y_batch.to(device).view(-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py:967\u001b[39m, in \u001b[36mOptimizer.zero_grad\u001b[39m\u001b[34m(self, set_to_none)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m         p.grad = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    969\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m p.grad.grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Choisir l'algorithme : 'fedavg', 'fedprox', 'fedopt_adam', 'fedopt_yogi', 'fedopt_adagrad'\n",
    "algo = 'fedavg'\n",
    "\n",
    "global_model, metrics = train_federated(\n",
    "    train_loaders=train_loaders,        # Une liste de DataLoader très petits (voir plus bas)\n",
    "    input_dim=input_dim,         # Un petit nombre de variables explicatives (par exemple 10)\n",
    "    algo='fedavg',                      # Pour commencer rapidement ; ensuite tester 'fedprox'\n",
    "    T=2,                                # Seulement 2 rounds fédérés\n",
    "    C=1.0,                              # Prendre tous les clients à chaque round\n",
    "    E=1,                                # Une seule époque locale\n",
    "    B=8,                                # Mini-batch de 8\n",
    "    lr=0.05,                            # Apprentissage local rapide\n",
    "    mu=0.0,                             # Pas de régularisation FedProx pour l’instant\n",
    "    eta=0.01,\n",
    "    beta1=0.9,\n",
    "    beta2=0.99,\n",
    "    tau=1e-6,\n",
    "    device='cpu'                        # Utiliser CPU pour compatibilité\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coefs = pd.DataFrame(metrics[\"coefficients\"], columns=[f\"var_{i}\" for i in range(input_dim)])\n",
    "coefs.plot(figsize=(10,6), title=\"Évolution des coefficients\")\n",
    "plt.xlabel(\"Round fédéré\")\n",
    "plt.ylabel(\"Valeur du coefficient\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a674cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des modèles locaux finaux\n",
    "local_models = get_local_models(train_loaders, global_model, E=3, B=32, lr=0.05, mu=0.1,\n",
    "                                global_weights=global_model.get_state_dict(), algo=algo, device=device)\n",
    "\n",
    "results = compare_global_local(global_model, local_models, train_loaders, device=device)\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_heatmap(local_models, train_loaders, title=f\"Heatmap AUC croisée - {algo.upper()}\", device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
